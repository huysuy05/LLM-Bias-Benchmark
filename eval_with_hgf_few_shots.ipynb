{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "37c3b204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c3b204",
        "outputId": "c3bf3289-1eac-4483-abdf-935a0fea770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.35.0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.10.0.dev20250916)\n",
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.56.2)\n",
            "Requirement already satisfied: hf-xet in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.1.10)\n",
            "Requirement already satisfied: bitsandbytes in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.42.0)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (4.66.5)\n",
            "Requirement already satisfied: sentence_transformers in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (5.1.0)\n",
            "Collecting mlx-lm (from -r requirements.txt (line 10))\n",
            "  Downloading mlx_lm-0.28.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (75.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 9)) (10.4.0)\n",
            "Collecting mlx>=0.29.2 (from mlx-lm->-r requirements.txt (line 10))\n",
            "  Downloading mlx-0.29.2-cp312-cp312-macosx_15_0_arm64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from mlx-lm->-r requirements.txt (line 10)) (4.25.3)\n",
            "Collecting mlx-metal==0.29.2 (from mlx>=0.29.2->mlx-lm->-r requirements.txt (line 10))\n",
            "  Downloading mlx_metal-0.29.2-py3-none-macosx_15_0_arm64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (2025.8.3)\n",
            "Downloading mlx_lm-0.28.1-py3-none-any.whl (282 kB)\n",
            "Downloading mlx-0.29.2-cp312-cp312-macosx_15_0_arm64.whl (548 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.3/548.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlx_metal-0.29.2-py3-none-macosx_15_0_arm64.whl (34.8 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mlx-metal, mlx, mlx-lm\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [mlx-lm]━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [mlx-lm]\n",
            "\u001b[1A\u001b[2KSuccessfully installed mlx-0.29.2 mlx-lm-0.28.1 mlx-metal-0.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "938c5b73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in /opt/anaconda3/lib/python3.12/site-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.56.2)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (2.10.0.dev20250916)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.5.1)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d805cace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d805cace",
        "outputId": "90eb2619-17c8-4673-b142-f0982a07752d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.56.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2830f7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libs\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sklearn.metrics import (\n",
        "    f1_score, recall_score, balanced_accuracy_score,\n",
        "    matthews_corrcoef, precision_score, average_precision_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9819c4eb",
      "metadata": {
        "id": "9819c4eb"
      },
      "outputs": [],
      "source": [
        "# Authenticate with HuggingFace\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "# from google.colab import userdata\n",
        "# hugging_face_token = userdata.get(\"hf_token\") #If using gg colab\n",
        "\n",
        "load_dotenv() #If using VSCode\n",
        "hugging_face_token = os.getenv(\"hf_token\") #If using VSCode\n",
        "\n",
        "login(token=hugging_face_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d2855d59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS device available: True\n",
            "Tensor allocated on MPS: mps:0\n"
          ]
        }
      ],
      "source": [
        "# Check memory allocated for MPS\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"MPS device available:\", torch.backends.mps.is_available())\n",
        "    # This tells you memory usage is not directly exposed, but you can monitor allocated tensors\n",
        "    x = torch.randn(1024, 1024, device=device)\n",
        "    print(\"Tensor allocated on MPS:\", x.device)\n",
        "else:\n",
        "    print(f\"CUDA device available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3542695",
      "metadata": {},
      "source": [
        "Load AG news datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "374a714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "374a714b",
        "outputId": "7a2bd586-6526-40b4-9073-bb9b2fa4cd28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stocks Set to Fall Amid High Oil Price  NEW YO...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ivory Coast Rebel Chief Brands Gbagbo War Crim...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bobcats 94 Hornets 93, overtime CHARLOTTE, NC ...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Colombian Far-Right Leader Gunned Down-Police ...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BHP Announces Record Annual Profit Anglo-Austr...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>Eight dead, 46 injured in French motorway pile...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>Boxing: Khan will keep feet on ground TEENAGE ...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>Mourinho joy at perfection Jose Mourinho said ...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>Stocks Up Despite Sluggish GDP Reading A slugg...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>Britain #39;s unluckiest punter dies A pension...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text     label\n",
              "0     Stocks Set to Fall Amid High Oil Price  NEW YO...  business\n",
              "1     Ivory Coast Rebel Chief Brands Gbagbo War Crim...     world\n",
              "2     Bobcats 94 Hornets 93, overtime CHARLOTTE, NC ...    sports\n",
              "3     Colombian Far-Right Leader Gunned Down-Police ...     world\n",
              "4     BHP Announces Record Annual Profit Anglo-Austr...  business\n",
              "...                                                 ...       ...\n",
              "3995  Eight dead, 46 injured in French motorway pile...     world\n",
              "3996  Boxing: Khan will keep feet on ground TEENAGE ...    sports\n",
              "3997  Mourinho joy at perfection Jose Mourinho said ...    sports\n",
              "3998  Stocks Up Despite Sluggish GDP Reading A slugg...  business\n",
              "3999  Britain #39;s unluckiest punter dies A pension...    sports\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {\n",
        "    0: \"world\",\n",
        "    1: \"sports\",\n",
        "    2: \"business\",\n",
        "    3: \"sci/tech\"\n",
        "}\n",
        "# Load existing prepared files (kept for reference)\n",
        "ag_news_imbalanced_data_99_to_1 = pd.read_parquet(\"./Data/ag_news/ag_news_train_imbalanced_99_to_1.parquet\")\n",
        "balanced_data = pd.read_parquet(\"./Data/ag_news/ag_news_train_balanced.parquet\")\n",
        "ag_news_imbalanced_data_49_to_1 = pd.read_parquet(\"./Data/ag_news/ag_news_train_imbalanced_49_to_1_ratio.parquet\")\n",
        "\n",
        "# Map numeric labels into text labels\n",
        "balanced_data[\"label\"] = balanced_data[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_99_to_1[\"label\"] = ag_news_imbalanced_data_99_to_1[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_49_to_1[\"label\"] = ag_news_imbalanced_data_49_to_1[\"label\"].map(label_map)\n",
        "\n",
        "# Shuffle the dataset\n",
        "ag_news_imbalanced_data_99_to_1 = ag_news_imbalanced_data_99_to_1.sample(frac=1).reset_index(drop=True)\n",
        "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
        "ag_news_imbalanced_data_49_to_1 = ag_news_imbalanced_data_49_to_1.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Utility: create imbalanced AG News dataset programmatically by choosing a majority label\n",
        "def split_ratio_for_ag_news(df, majority_label, majority_count, minority_count):\n",
        "    \"\"\"Create an imbalanced AG News subset where `majority_label` has `majority_count` samples\"\"\"\n",
        "    parts = []\n",
        "    labels = df['label'].unique().tolist()\n",
        "    for lab in labels:\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            # sample minority_count from each other class\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "ag_news_world_majority_99 = split_ratio_for_ag_news(balanced_data, 'world', majority_count=980, minority_count=20)\n",
        "ag_news_sports_majority_99 = split_ratio_for_ag_news(balanced_data, 'sports', majority_count=980, minority_count=20)\n",
        "ag_news_business_majority_99 = split_ratio_for_ag_news(balanced_data, 'business', majority_count=980, minority_count=20)\n",
        "\n",
        "# Keep original balanced_data as the balanced dataset\n",
        "# Testing\n",
        "balanced_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3b27bc",
      "metadata": {},
      "source": [
        "Load toxic text dataset (The dataset is already imbalanced)\n",
        "\n",
        "- Rename the columns to have the same names as other datasets\n",
        "- Label = 0 --> Not toxic\n",
        "- Label = 1 --> Toxic\n",
        "- Map label column into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "afb89ef6",
      "metadata": {},
      "outputs": [],
      "source": [
        "toxic_label_map = {\n",
        "    0: \"nontoxic\",\n",
        "    1: \"toxic\"\n",
        "}\n",
        "\n",
        "def split_ratio_for_toxic_dataset(df, majority_label='nontoxic', majority_count=500, minority_count=20):\n",
        "    \"\"\"Create an imbalanced toxic_text subset where `majority_label` has `majority_count` samples and the other label has `minority_count`.\"\"\"\n",
        "    parts = []\n",
        "    for lab in df['label'].unique():\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "toxic_text = pd.read_csv(\"Data/toxic_text/train.csv\")\n",
        "toxic_text = toxic_text[[\"comment_text\", \"toxic\"]]\n",
        "toxic_text = toxic_text.rename(columns={\"comment_text\": \"text\", \"toxic\": \"label\"})\n",
        "toxic_text[\"label\"] = toxic_text[\"label\"].map(toxic_label_map)\n",
        "\n",
        "# Get 3 small subsets of the main datasets with 3 different ratios and different majority classes\n",
        "toxic_balanced = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=500, minority_count=500)\n",
        "# Increase minority_count to 20 as requested\n",
        "toxic_99_to_1 = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=980, minority_count=20)\n",
        "toxic_49_to_1 = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=940, minority_count=20)\n",
        "toxic_toxic_majority_99 = split_ratio_for_toxic_dataset(toxic_text, majority_label='toxic', majority_count=980, minority_count=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c04be3d",
      "metadata": {},
      "source": [
        "Load twitter emotion type dataset (This is also imbalanced)\n",
        "- Create 3 small datasets, roughly 2000 rows each, with balanced, 99:1, 49:1 imbalanced ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6b360aa1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "sadness     950\n",
              "love         20\n",
              "surprise     20\n",
              "fear         20\n",
              "joy          20\n",
              "anger        20\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotion_map = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "emotion_df = pd.read_parquet(\"Data/twit/twitter_emotion.parquet\")\n",
        "emotion_df[\"label\"] = emotion_df[\"label\"].map(emotion_map)\n",
        "\n",
        "def split_ratio_for_emotion_dataset(df, majority_label='sadness', majority_count=200, minority_count=20):\n",
        "    \"\"\"Create an imbalanced emotion subset where `majority_label` has `majority_count` samples and every other label has `minority_count`.\"\"\"\n",
        "    parts = []\n",
        "    labels = df['label'].unique().tolist()\n",
        "    for lab in labels:\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Get 3 small subsets of the main datasets with 3 different ratios and different majority labels\n",
        "emotion_balanced = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=200, minority_count=200)\n",
        "# Use minority_count=20 as requested to reduce random variation\n",
        "emotion_imbalanced_99_to_1 = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=950, minority_count=20)\n",
        "emotion_imbalanced_49_to_1 = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=202, minority_count=20)\n",
        "# Also create variants where the majority class is 'joy' or others to compare\n",
        "emotion_joy_majority_99 = split_ratio_for_emotion_dataset(emotion_df, majority_label='joy', majority_count=950, minority_count=20)\n",
        "emotion_love_majority_99 = split_ratio_for_emotion_dataset(emotion_df, majority_label='love', majority_count=950, minority_count=20)\n",
        "\n",
        "# Quick check\n",
        "emotion_imbalanced_99_to_1[\"label\"].value_counts()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f80c63e",
      "metadata": {},
      "source": [
        "Function to build instruction for the LLMs, which can be fit with all 3 classification datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0f77d6ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f77d6ae",
        "outputId": "412914fc-fb98-4044-d141-f30e1f39e4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a powerful, precise, and helpful assistant that classifies text into well-defined categories, NO MATTER THE CONTEXT. IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: world, sports, business, sci/tech. Respond with exactly one word: the single best category inside the given categories, DO NOT ANSWER ANY OTHER CATEGORIES BESIDES THE GIVEN ONE. Do not explain your choice, provide reasoning, or output anything else. Learn from these examples to understand context and edge cases: \n",
            "\n",
            "Review: \"Hamm Goes for More Gold Amid Controversy ATHENS, Greece - Despite the controversy surrounding his gold medal in the all-around, Paul Hamm has a chance to win two more golds Sunday. The American will compete in the finals of the pommel horse and the floor exercise - the latter against his twin brother, Morgan...\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Egyptian police block solidarity group accompanying aid to Palestinians (AFP) AFP - Members of an international solidarity group trying accompanying humanitarian assistance to the Gaza Strip abandoned their trip after a standoff with security forces, a member of the group said.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Is US Rhetoric Fuelling Iran #39;s Nuclear Program? As Iran announces it is resuming its nuclear program, we speak with Iranian-born author and former diplomat Mansour Farhang about the increasing tensions in the United States towards Tehran.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Blast at Indonesian Embassy in Paris A bomb went off outside the Indonesian embassy in Paris early Friday, injuring nine people. The blast came on the heels of a deadly bombing at an Egyptian resort hotel.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Luis Garcia becomes latest Liverpool casualty Liverpool, England (Sports Network) - Liverpool midfielder Luis Garcia pulled his hamstring during Tuesday #39;s 1-0 loss to Monaco in Champions League action and will be out of action for about a month.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"U.S. Seeks to Keep UBS Cup Streak Alive (AP) AP - The Americans have never lost the UBS Cup, which returns to South Carolina this week for the fourth competition in the Ryder Cup-style event.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Final round within reach for Americans WASHINGTON -- The heavy lifting has been done. The long plane rides to exotic lands and the tough nights on the road playing in front of raucous crowds are a memory for now.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Tendulkar could open bowling in final test v Australia India are considering the high risk strategy of asking Sachin Tendulkar to open the bowling for the first time in his career and selecting three spinners for the \"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Amex mounts lawsuit over  #39;cards cartel #39; American Express yesterday said it was seeking  quot;billions of dollars quot; in damages from Visa and MasterCard over alleged  quot;illegal and anticompetitive practices quot;.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Phil Knight to resign as CEO of Nike Worldwide athletic-goods giant Nike, Inc. announced Thursday that University alumnus and current Chairman and Chief Executive Officer Philip H. Knight will step down as CEO, effective Dec. 28.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Bangladesh Is Surviving to Export Another Day Garment makers in poor countries have been dismayed over the upcoming abolition of trade quotas, but the outlook is not as bleak as many experts had thought.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Zale Sees Deeper Loss, Hurricanes Hurt  NEW YORK (Reuters) - Jeweler Zale Corp. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=ZLC.N target=/stocks/quickinfo/fullquote\"&gt;ZLC.N&lt;/A&gt; on Thursday  said its quarterly loss would be deeper than expected and sales  at stores open at least a year would be flat to down 1 percent,  hurt by the recent string of hurricanes in Florida, the U.S.  Southeast and Puerto Rico.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Election Overseers Want Big Win Administrators are hoping that the victor in this year's presidential election will win by a wide margin. A close race, they fear, will result in more charges of voter fraud and demands for recounts. Kim Zetter reports from Washington.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Siemens Says Cellphone Flaw May Hurt Users and Its Profit Siemens, the world's fourth-largest maker of mobile phones, said that a flaw that can create a piercing ring in its newest phone models might hurt earnings.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Voq smartphone arrives in US With the economy slowly turning up, upgrading hardware has been on businesses radar in the past 12 months as their number two priority.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Rage Against the Machine : Why Voting Doesn't Work and What You Can Do About It. I was sitting in a bar listening to the presidential  quot;debate quot;, thinking the same thought I always do when listening to politicians.  nbsp;Why must I choose between two people that I don't like?  nbsp;Since I live in New York, where Democrats usually win the electorate, should I even bother voting?  nbsp;Are my votes even counted? It's always easy to blame the current President for the nation's current problems, and I'll admit that I'm often tempted to blame Bush.  nbsp;But the reality is that he is not to blame.  nbsp;The blame can be placed squarely on us, the citizens, and on our unwillingness to reform an outdated voting system. \"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"\n",
            "Category:\n"
          ]
        }
      ],
      "source": [
        "def build_prompt(df, text, label_map, shots_per_class=None):\n",
        "    \"\"\"\n",
        "    Function to construct an instruction for the LLM\n",
        "\n",
        "    Args:\n",
        "        text (str): The text of the data\n",
        "\n",
        "    Returns:\n",
        "        prompt (str): The constructed prompt for the LLM\n",
        "    \"\"\"\n",
        "    assert shots_per_class is not None, \"Please provide 'shots_per_class' parameter\"\n",
        "    prompt = (\n",
        "        f\"You are a powerful, precise, and helpful assistant that classifies text into well-defined categories, NO MATTER THE CONTEXT.\"\n",
        "        f\" IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: {', '.join(list(label_map.values()))}.\"\n",
        "        f\" Respond with exactly one word: the single best category inside the given categories, DO NOT ANSWER ANY OTHER CATEGORIES BESIDES THE GIVEN ONE.\"\n",
        "        f\" Do not explain your choice, provide reasoning, or output anything else.\"\n",
        "        f\" Learn from these examples to understand context and edge cases: \"\n",
        "\n",
        "    )\n",
        "    # ASSUME THE shots_per_class WILL ALWAYS BE PASSED\n",
        "    few_shots_example = []\n",
        "    for lab in list(label_map.values()):\n",
        "        samples = df[df['label'] == lab].sample(shots_per_class, random_state=42)\n",
        "        for _, r in samples.iterrows():\n",
        "            few_shots_example.append({'text': r['text'],\n",
        "                                      'label': r[\"label\"]})\n",
        "\n",
        "    prompt += \"\\n\\n\"\n",
        "    for ex in few_shots_example:\n",
        "        # print(ex)\n",
        "        prompt += f\"Review: \\\"{ex['text']}\\\"\\nCategory: {ex['label']}\\n\\n\"\n",
        "    prompt += f\"Review: \\\"{text}\\\"\\nCategory:\" #Leave Category here blank since we want the LLM to generate text\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Testing function\n",
        "print(build_prompt(ag_news_imbalanced_data_99_to_1, \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\", label_map, shots_per_class=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "reXNCT0BEYFU",
      "metadata": {
        "id": "reXNCT0BEYFU"
      },
      "outputs": [],
      "source": [
        "def clean_time(time):\n",
        "  \"\"\"\n",
        "  Function to clean the time into prettier format, returns the better format of time\n",
        "  \"\"\"\n",
        "  if time <= 60:\n",
        "    return f\"{time} seconds.\"\n",
        "\n",
        "  minutes = time // 60\n",
        "  remain_sec = time - minutes * 60\n",
        "  return f\"{minutes} minutes, {remain_sec:.2f} seconds.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860a8548",
      "metadata": {},
      "source": [
        "Label normalization using semantic similarity\n",
        "- Since we have 3 datasets, using manual variation map will not ensure every predictions that the LLM makes\n",
        "- So we load a sentence embedding model to calculate the nearest vector amongst the label using Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "240e9e2d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anger\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Testing with AG News\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Ag news\n",
        "valid_labs_ag_news = list(label_map.values())\n",
        "valid_embeddings_ag_news = embedding_model.encode(valid_labs_ag_news, convert_to_tensor=True)\n",
        "\n",
        "# Toxic Text\n",
        "valid_labs_toxic_text = list(toxic_label_map.values())\n",
        "valid_embeddings_toxic_text = embedding_model.encode(valid_labs_toxic_text, convert_to_tensor=True)\n",
        "\n",
        "# Twitter Emotion\n",
        "valid_labs_emotion = list(emotion_map.values())\n",
        "valid_embeddings_emotion = embedding_model.encode(valid_labs_emotion, convert_to_tensor=True)\n",
        "\n",
        "def normalize(label, valid_embeddings, valid_labs):\n",
        "    pred_emb = embedding_model.encode(label, convert_to_tensor=True)\n",
        "    cos_scores = util.cos_sim(pred_emb, valid_embeddings)[0]\n",
        "    closest_idx = cos_scores.argmax().item()\n",
        "    return valid_labs[closest_idx]\n",
        "\n",
        "# Testing for AG News\n",
        "raw_preds = \"Pissed off\"\n",
        "normalized_preds = normalize(raw_preds, valid_embeddings=valid_embeddings_emotion, valid_labs=valid_labs_emotion)\n",
        "print(normalized_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9249686c",
      "metadata": {
        "id": "9249686c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import pipeline, logging\n",
        "from time import time\n",
        "\n",
        "\n",
        "# Load model\n",
        "\n",
        "\n",
        "# CREATE A FUNCTION TO RUN CLASSFICATION\n",
        "def classify(model, df, label_map, shots, batch_size=16, max_new_tokens=3, valid_embeddings=None, valid_labs=None):\n",
        "    \"\"\"\n",
        "    Function to run classification with different number of shots\n",
        "\n",
        "    Args:\n",
        "        model (str): name of the model\n",
        "        tokenizer\n",
        "        df (pd.DataFrame): the pandas dataframe\n",
        "        batch_size (int): batch size per run\n",
        "\n",
        "    Returns:\n",
        "        pred_arr (List[str]): the array that contains all predictions\n",
        "    \"\"\"\n",
        "    # Initiate a pipeline for each dataset\n",
        "    # USE text2text-generation for the gemma model\n",
        "    # USE text-generation for the others, or text-classification\n",
        "    # USE fill-mask for distillbert\n",
        "    pipe = pipeline(\"text-generation\", model=model, dtype=torch.float16)\n",
        "    logging.set_verbosity_error()\n",
        "\n",
        "    # Generate prompts for all rows\n",
        "    prompts = [build_prompt(df, text, label_map, shots_per_class=shots) for text in df[\"text\"]]\n",
        "\n",
        "    # Run the pipeline for each row\n",
        "    pred_arr = []\n",
        "    start_time = time()\n",
        "\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = prompts[i:i + batch_size] #slices a sublist of prompts\n",
        "        results = pipe(batch, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "        for prompt, res in zip(batch, results):\n",
        "            pred = res[0]['generated_text'][len(prompt):].strip().lower().split()\n",
        "            # print(f\"Real value: {df[\"label\"]}\")\n",
        "            # print(f\"Predicted value: {pred}\")\n",
        "            if pred[0] not in list(label_map.values()):\n",
        "                normalized_pred = normalize(pred[0], valid_embeddings=valid_embeddings, valid_labs=valid_labs)\n",
        "                pred_arr.append(normalized_pred)\n",
        "            else:\n",
        "                pred_arr.append(pred[0]) #Use pred[0] for some cases\n",
        "    end_time = time()\n",
        "\n",
        "    total_time = clean_time(end_time - start_time)\n",
        "\n",
        "    print(\"Total running time is \" + total_time)\n",
        "    return pred_arr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f87464c",
      "metadata": {},
      "source": [
        "Function to compute all metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "75345a5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pass list(df[\"text\"]) for y_true\n",
        "# list(label_map.values())\n",
        "\n",
        "def eval_llm(y_true, y_pred, label_map):\n",
        "    y_true_arr = np.array([x.lower().strip() for x in y_true])\n",
        "    # print(y_pred)  # avoid noisy output\n",
        "    y_pred_arr = np.array([x.lower().strip() for x in y_pred])\n",
        "\n",
        "    labels = [lab.lower() for lab in list(label_map.values())]\n",
        "\n",
        "    # Calculate macro scores:\n",
        "    macro_f1 = f1_score(y_true_arr, y_pred_arr, labels=labels, zero_division=0, average='macro')\n",
        "    macro_recall = recall_score(y_true_arr, y_pred_arr, labels=labels, average='macro', zero_division=0)\n",
        "    bal_acc = balanced_accuracy_score(y_true_arr, y_pred_arr)\n",
        "    mcc = matthews_corrcoef(y_true_arr, y_pred_arr)\n",
        "\n",
        "    # Calculate per-class precision, recall, f1 (returns arrays aligned with labels)\n",
        "    precision_per_class_vals = precision_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "    recall_per_class_vals = recall_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "    f1_per_class_vals = f1_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "\n",
        "    precision_per_class = {}\n",
        "    recall_per_class = {}\n",
        "    f1_per_class = {}\n",
        "    for idx, cls in enumerate(labels):\n",
        "        precision_per_class[cls] = float(precision_per_class_vals[idx])\n",
        "        recall_per_class[cls] = float(recall_per_class_vals[idx])\n",
        "        f1_per_class[cls] = float(f1_per_class_vals[idx])\n",
        "\n",
        "    # Calculate AUPRC per class\n",
        "    y_true_bin = label_binarize(y_true_arr, classes=labels)\n",
        "    y_pred_bin = label_binarize(y_pred_arr, classes=labels)\n",
        "    if len(labels) == 2 and y_true_bin.shape[1] == 1:\n",
        "        y_true_bin = np.hstack([1 - y_true_bin, y_true_bin])\n",
        "        y_pred_bin = np.hstack([1 - y_pred_bin, y_pred_bin])\n",
        "\n",
        "    auprc_per_class = {}\n",
        "    for idx, cls in enumerate(labels):\n",
        "        ap = average_precision_score(y_true_bin[:, idx], y_pred_bin[:, idx])\n",
        "        auprc_per_class[cls] = float(ap)\n",
        "\n",
        "    return {\n",
        "        \"macro_f1\": float(macro_f1),\n",
        "        \"macro_recall\": float(macro_recall),\n",
        "        \"balanced_accuracy\": float(bal_acc),\n",
        "        \"mcc\": float(mcc),\n",
        "        \"auprc_per_class\": auprc_per_class,\n",
        "        \"precision_per_class\": precision_per_class,\n",
        "        \"recall_per_class\": recall_per_class,\n",
        "        \"f1_per_class\": f1_per_class\n",
        "    }\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875bcf38",
      "metadata": {},
      "source": [
        "NOW FOCUSING ON QWEN2.5 INSTRUCT MODEDLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "eb1247a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1247a0",
        "outputId": "bb995908-9dff-4b54-ee56-911de09e93c9"
      },
      "outputs": [],
      "source": [
        "# model, df, label_map, shots, batch_size=8, max_new_tokens=3\n",
        "def run_experiments(model, datasets_dict, dataset_name, label_map, shots_list=[2,4,8], batch_size=16, valid_embeddings=None, valid_labs=None):\n",
        "    import os\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    import numpy as _np\n",
        "    import pandas as _pd\n",
        "\n",
        "    def infer_meta(ds_name, df):\n",
        "        # Try to infer ratio and majority label from the dataset name using heuristics\n",
        "        ratio = 'unknown'\n",
        "        maj_label = 'unknown'\n",
        "\n",
        "        # Check common name patterns\n",
        "        if 'balanced' in ds_name:\n",
        "            ratio = 'balanced'\n",
        "        m = re.search(r\"(\\d+)_to_(\\d+)\", ds_name)\n",
        "        if m:\n",
        "            ratio = f\"{m.group(1)}:{m.group(2)}\"\n",
        "\n",
        "        # look for \"_majority_\" pattern like 'world_majority_99'\n",
        "        m2 = re.search(r\"([A-Za-z0-9]+)_majority\", ds_name)\n",
        "        if m2:\n",
        "            maj_label = m2.group(1)\n",
        "\n",
        "        # fallback: infer from df counts\n",
        "        try:\n",
        "            counts = df['label'].value_counts()\n",
        "            if len(counts) > 0:\n",
        "                maj_label_from_df = counts.idxmax()\n",
        "                if maj_label == 'unknown':\n",
        "                    maj_label = str(maj_label_from_df)\n",
        "                # compute numeric ratio using most common and the minimum of others\n",
        "                maj_count = int(counts.max())\n",
        "                others = counts.drop(maj_label_from_df)\n",
        "                if len(others) > 0:\n",
        "                    min_count = int(others.min())\n",
        "                else:\n",
        "                    min_count = 0\n",
        "                ratio = f\"{maj_count}:{min_count}\"\n",
        "        except Exception:\n",
        "            # keep heuristics result\n",
        "            pass\n",
        "\n",
        "        return ratio, maj_label\n",
        "\n",
        "    results = []\n",
        "    # Ensure results folder exists for this dataset\n",
        "    out_dir = os.path.join(\"results\", dataset_name)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ds_name, df in datasets_dict.items():\n",
        "        print(f\"=== RUNNING DATASET {ds_name} ===\")\n",
        "        test_df = df.sample(frac=1).reset_index(drop=True)\n",
        "        for shots in shots_list:\n",
        "            print(f\"    === SHOTS = {shots} ===\")\n",
        "            preds = classify(model, test_df, label_map, shots=shots, batch_size=batch_size, valid_embeddings=valid_embeddings, valid_labs=valid_labs)\n",
        "            metrics = eval_llm(test_df['label'].tolist(), preds, label_map=label_map)\n",
        "\n",
        "            # infer dataset metadata\n",
        "            ratio, maj_label = infer_meta(ds_name, df)\n",
        "\n",
        "            row = {\n",
        "                \"model\": model,\n",
        "                \"dataset\": ds_name,\n",
        "                \"shots\": shots,\n",
        "                \"dataset_ratio\": ratio,\n",
        "                \"majority_label\": maj_label,\n",
        "                **metrics\n",
        "            }\n",
        "            results.append(row)\n",
        "\n",
        "            # Create a flattened aggregated DataFrame for better CSV readability\n",
        "            df_agg = _pd.json_normalize(results)\n",
        "            # replace dots in column names (from nested dicts) with underscores\n",
        "            df_agg.columns = [c.replace('.', '_') for c in df_agg.columns]\n",
        "\n",
        "\n",
        "            agg_name = f\"few_shot_results_{model.replace('/','_')}.csv\"\n",
        "            agg_path = os.path.join(out_dir, agg_name)\n",
        "            df_agg.to_csv(agg_path, index=False)\n",
        "\n",
        "            # New per-params file: group by (model, ds_name, ratio, maj_label, shots)\n",
        "            safe_model = model.replace('/', '_')\n",
        "            safe_ds_name = ds_name.replace(' ', '_')\n",
        "            safe_maj = str(maj_label).replace(' ', '_').replace('/', '_')\n",
        "            ratio_safe = str(ratio).replace(':', '-')\n",
        "            params_fname = f\"results__{safe_model}__{safe_ds_name}__ratio-{ratio_safe}__majority-{safe_maj}__shots-{shots}.csv\"\n",
        "            params_path = os.path.join(out_dir, params_fname)\n",
        "\n",
        "            # Flatten the current row and append to the per-params CSV (create if not exists)\n",
        "            flat_row_df = _pd.json_normalize([row])\n",
        "            flat_row_df.columns = [c.replace('.', '_') for c in flat_row_df.columns]\n",
        "\n",
        "            if _pd.io.common.file_exists(params_path):\n",
        "                # append without header\n",
        "                flat_row_df.to_csv(params_path, mode='a', header=False, index=False)\n",
        "            else:\n",
        "                flat_row_df.to_csv(params_path, index=False)\n",
        "\n",
        "    return _pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Y_Ligz6iBlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ligz6iBlf7",
        "outputId": "3563a9ba-7a5d-4af5-c1fa-0db052027417"
      },
      "outputs": [],
      "source": [
        "# Create a dataset dict for easy mapping\n",
        "\n",
        "ag_news_datasets_dict = {\n",
        "    \"ag_news_balanced\": balanced_data,\n",
        "    \"ag_news_imbalanced_data_99_to_1\": ag_news_imbalanced_data_99_to_1,\n",
        "    \"ag_news_imbalanced_data_49_to_1\": ag_news_imbalanced_data_49_to_1,\n",
        "    # Variants where a specific class is the majority (minority_count=20)\n",
        "    \"ag_news_world_majority_99\": ag_news_world_majority_99,\n",
        "    \"ag_news_sports_majority_99\": ag_news_sports_majority_99,\n",
        "    \"ag_news_business_majority_99\": ag_news_business_majority_99\n",
        "}\n",
        "\n",
        "toxic_datasets_dict = {\n",
        "    \"toxic_text\": toxic_balanced,\n",
        "    \"toxic_99_to_1\": toxic_99_to_1,\n",
        "    \"toxic_49_to_1\": toxic_49_to_1,\n",
        "    \"toxic_toxic_majority_99\": toxic_toxic_majority_99\n",
        "}\n",
        "\n",
        "emotion_datasets_dict = {\n",
        "    \"emotion_df\": emotion_balanced,\n",
        "    \"emotion_imbalanced_99_to_1\": emotion_imbalanced_99_to_1,\n",
        "    \"emotion_imbalanced_49_to_1\": emotion_imbalanced_49_to_1,\n",
        "    \"emotion_joy_majority_99\": emotion_joy_majority_99,\n",
        "    \"emotion_love_majority_99\": emotion_love_majority_99\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05c9ba5",
      "metadata": {},
      "source": [
        "Run models + evals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7023ccac",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"Qwen/Qwen2.5-1B-Instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1457c6",
      "metadata": {},
      "source": [
        "Quantize model (Optional)\n",
        "- Use subprocess library to run shell script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8b02dc47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /Volumes/huysuy05/Projects/Bias_of_LLMs\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "script_path = Path(\"scripts/convert.py\")\n",
        "print(\"cwd:\", Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26f8745",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'python scripts/convert.py --hf-path Qwen/Qwen2.5-1B-Instruct'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m scripts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython scripts/convert.py --hf-path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     res \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun([scripts], capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTDOUT: \u001b[39m\u001b[38;5;124m\"\u001b[39m, res\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTDERR: \u001b[39m\u001b[38;5;124m\"\u001b[39m, res\u001b[38;5;241m.\u001b[39mstderr)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1032\u001b[0m                         restore_signals,\n\u001b[1;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'python scripts/convert.py --hf-path Qwen/Qwen2.5-1B-Instruct'"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "cmd = [\"python\", str(script_path), \"--hf-path\", model]\n",
        "\n",
        "try:\n",
        "    res = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"STDOUT: \", res.stdout)\n",
        "    print(\"STDERR: \", res.stderr)\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Script failed with error: {e}\")\n",
        "    print(\"STDOUT:\", e.stdout)\n",
        "    print(\"STDERR:\", e.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1587a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN AG NEWS DATASET\n",
        "\n",
        "res_df = run_experiments(model, ag_news_datasets_dict, 'ag_news',label_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_ag_news, valid_labs=valid_labs_ag_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bab41c3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running time is 3.0 minutes, 3.63 seconds.\n",
            "Total running time is 5.0 minutes, 25.82 seconds.\n",
            "Total running time is 5.0 minutes, 25.82 seconds.\n",
            "Total running time is 19.0 minutes, 25.56 seconds.\n",
            "Total running time is 19.0 minutes, 25.56 seconds.\n",
            "Total running time is 3.0 minutes, 6.27 seconds.\n",
            "Total running time is 3.0 minutes, 6.27 seconds.\n",
            "Total running time is 3.0 minutes, 52.05 seconds.\n",
            "Total running time is 3.0 minutes, 52.05 seconds.\n",
            "Total running time is 8.0 minutes, 20.48 seconds.\n",
            "Total running time is 8.0 minutes, 20.48 seconds.\n",
            "Total running time is 6.0 minutes, 36.43 seconds.\n",
            "Total running time is 6.0 minutes, 36.43 seconds.\n",
            "Total running time is 8.0 minutes, 3.82 seconds.\n",
            "Total running time is 8.0 minutes, 3.82 seconds.\n",
            "Total running time is 11.0 minutes, 49.07 seconds.\n",
            "Total running time is 11.0 minutes, 49.07 seconds.\n",
            "Total running time is 3.0 minutes, 35.71 seconds.\n",
            "Total running time is 3.0 minutes, 35.71 seconds.\n",
            "Total running time is 4.0 minutes, 24.03 seconds.\n",
            "Total running time is 4.0 minutes, 24.03 seconds.\n",
            "Total running time is 6.0 minutes, 57.34 seconds.\n",
            "Total running time is 6.0 minutes, 57.34 seconds.\n"
          ]
        }
      ],
      "source": [
        "# RUN TOXIC TEXT DATASET\n",
        "res_df = run_experiments(model, toxic_datasets_dict, \"toxic_text\",toxic_label_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_toxic_text, valid_labs=valid_labs_toxic_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b524933f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running time is 4.0 minutes, 19.29 seconds.\n",
            "Total running time is 6.0 minutes, 52.41 seconds.\n",
            "Total running time is 6.0 minutes, 52.41 seconds.\n",
            "Total running time is 13.0 minutes, 36.03 seconds.\n",
            "Total running time is 13.0 minutes, 36.03 seconds.\n",
            "Total running time is 3.0 minutes, 44.12 seconds.\n",
            "Total running time is 3.0 minutes, 44.12 seconds.\n",
            "Total running time is 6.0 minutes, 2.84 seconds.\n",
            "Total running time is 6.0 minutes, 2.84 seconds.\n",
            "Total running time is 11.0 minutes, 41.76 seconds.\n",
            "Total running time is 11.0 minutes, 41.76 seconds.\n",
            "Total running time is 1.0 minutes, 3.09 seconds.\n",
            "Total running time is 1.0 minutes, 3.09 seconds.\n",
            "Total running time is 1.0 minutes, 39.83 seconds.\n",
            "Total running time is 1.0 minutes, 39.83 seconds.\n",
            "Total running time is 3.0 minutes, 39.79 seconds.\n",
            "Total running time is 3.0 minutes, 39.79 seconds.\n",
            "Total running time is 4.0 minutes, 11.16 seconds.\n",
            "Total running time is 6.0 minutes, 41.76 seconds.\n",
            "Total running time is 11.0 minutes, 45.36 seconds.\n",
            "Total running time is 3.0 minutes, 48.12 seconds.\n",
            "Total running time is 6.0 minutes, 8.81 seconds.\n",
            "Total running time is 12.0 minutes, 48.41 seconds.\n"
          ]
        }
      ],
      "source": [
        "# RUN TWITTER EMOTION DATASET\n",
        "res_df = run_experiments(model, emotion_datasets_dict, 'twitter_emotion', emotion_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_emotion, valid_labs=valid_labs_emotion)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

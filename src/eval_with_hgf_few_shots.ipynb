{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "37c3b204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c3b204",
        "outputId": "c3bf3289-1eac-4483-abdf-935a0fea770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (0.35.0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (2.10.0.dev20250916)\n",
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (4.56.2)\n",
            "Requirement already satisfied: hf-xet in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (1.1.10)\n",
            "Requirement already satisfied: bitsandbytes in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (0.42.0)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (4.66.5)\n",
            "Requirement already satisfied: sentence_transformers in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (5.1.0)\n",
            "Requirement already satisfied: mlx-lm in /opt/anaconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (0.28.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r ../requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r ../requirements.txt (line 4)) (75.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r ../requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r ../requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r ../requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r ../requirements.txt (line 5)) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r ../requirements.txt (line 5)) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r ../requirements.txt (line 5)) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers->-r ../requirements.txt (line 9)) (10.4.0)\n",
            "Requirement already satisfied: mlx>=0.29.2 in /opt/anaconda3/lib/python3.12/site-packages (from mlx-lm->-r ../requirements.txt (line 10)) (0.29.2)\n",
            "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from mlx-lm->-r ../requirements.txt (line 10)) (4.25.3)\n",
            "Requirement already satisfied: mlx-metal==0.29.2 in /opt/anaconda3/lib/python3.12/site-packages (from mlx>=0.29.2->mlx-lm->-r ../requirements.txt (line 10)) (0.29.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r ../requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->-r ../requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r ../requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r ../requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r ../requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r ../requirements.txt (line 1)) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install -r \"../requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "938c5b73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in /opt/anaconda3/lib/python3.12/site-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.56.2)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (2.10.0.dev20250916)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.5.1)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence_transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d805cace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d805cace",
        "outputId": "90eb2619-17c8-4673-b142-f0982a07752d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.56.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2830f7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libs\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sklearn.metrics import (\n",
        "    f1_score, recall_score, balanced_accuracy_score,\n",
        "    matthews_corrcoef, precision_score, average_precision_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9819c4eb",
      "metadata": {
        "id": "9819c4eb"
      },
      "outputs": [],
      "source": [
        "# Authenticate with HuggingFace\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "# from google.colab import userdata\n",
        "# hugging_face_token = userdata.get(\"hf_token\") #If using gg colab\n",
        "\n",
        "load_dotenv() #If using VSCode\n",
        "hugging_face_token = os.getenv(\"hf_token\") #If using VSCode\n",
        "\n",
        "login(token=hugging_face_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d2855d59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS device available: True\n",
            "Tensor allocated on MPS: mps:0\n"
          ]
        }
      ],
      "source": [
        "# Check memory allocated for MPS\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"MPS device available:\", torch.backends.mps.is_available())\n",
        "    # This tells you memory usage is not directly exposed, but you can monitor allocated tensors\n",
        "    x = torch.randn(1024, 1024, device=device)\n",
        "    print(\"Tensor allocated on MPS:\", x.device)\n",
        "else:\n",
        "    print(f\"CUDA device available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3542695",
      "metadata": {},
      "source": [
        "Load AG news datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "374a714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "374a714b",
        "outputId": "7a2bd586-6526-40b4-9073-bb9b2fa4cd28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7 Marines Killed in Iraq's Anbar Province (AP)...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Things better without Conway? PeopleSoft Inc.,...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tim Carter out for season Tim Carter, the Gian...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Eyeing the next wave in RISC computing Some cr...</td>\n",
              "      <td>sci/tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marbury and Late Timeout Are Upsetting to Span...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>Nigerian Oil Delta Rebels Say 'War' to Start O...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>Homeland Security Names New Cyber Chief By 1:5...</td>\n",
              "      <td>sci/tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>WTO Rules US Must Allow Online Gambling Antigu...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>Alleged vigilantes show videos of US, UN conta...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>Car bomb kills five at Iraq education ministry...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text     label\n",
              "0     7 Marines Killed in Iraq's Anbar Province (AP)...     world\n",
              "1     Things better without Conway? PeopleSoft Inc.,...  business\n",
              "2     Tim Carter out for season Tim Carter, the Gian...    sports\n",
              "3     Eyeing the next wave in RISC computing Some cr...  sci/tech\n",
              "4     Marbury and Late Timeout Are Upsetting to Span...    sports\n",
              "...                                                 ...       ...\n",
              "3995  Nigerian Oil Delta Rebels Say 'War' to Start O...     world\n",
              "3996  Homeland Security Names New Cyber Chief By 1:5...  sci/tech\n",
              "3997  WTO Rules US Must Allow Online Gambling Antigu...  business\n",
              "3998  Alleged vigilantes show videos of US, UN conta...     world\n",
              "3999  Car bomb kills five at Iraq education ministry...     world\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {\n",
        "    0: \"world\",\n",
        "    1: \"sports\",\n",
        "    2: \"business\",\n",
        "    3: \"sci/tech\"\n",
        "}\n",
        "# Load existing prepared files (kept for reference)\n",
        "ag_news_imbalanced_data_99_to_1 = pd.read_parquet(\"../Data/ag_news/ag_news_train_imbalanced_99_to_1.parquet\")\n",
        "balanced_data = pd.read_parquet(\"../Data/ag_news/ag_news_train_balanced.parquet\")\n",
        "ag_news_imbalanced_data_49_to_1 = pd.read_parquet(\"../Data/ag_news/ag_news_train_imbalanced_49_to_1_ratio.parquet\")\n",
        "\n",
        "# Map numeric labels into text labels\n",
        "balanced_data[\"label\"] = balanced_data[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_99_to_1[\"label\"] = ag_news_imbalanced_data_99_to_1[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_49_to_1[\"label\"] = ag_news_imbalanced_data_49_to_1[\"label\"].map(label_map)\n",
        "\n",
        "# Shuffle the dataset\n",
        "ag_news_imbalanced_data_99_to_1 = ag_news_imbalanced_data_99_to_1.sample(frac=1).reset_index(drop=True)\n",
        "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
        "ag_news_imbalanced_data_49_to_1 = ag_news_imbalanced_data_49_to_1.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Utility: create imbalanced AG News dataset programmatically by choosing a majority label\n",
        "def split_ratio_for_ag_news(df, majority_label, majority_count, minority_count):\n",
        "    \"\"\"Create an imbalanced AG News subset where `majority_label` has `majority_count` samples\"\"\"\n",
        "    parts = []\n",
        "    labels = df['label'].unique().tolist()\n",
        "    for lab in labels:\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            # sample minority_count from each other class\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "ag_news_world_majority_99 = split_ratio_for_ag_news(balanced_data, 'world', majority_count=980, minority_count=20)\n",
        "ag_news_sports_majority_99 = split_ratio_for_ag_news(balanced_data, 'sports', majority_count=980, minority_count=20)\n",
        "ag_news_business_majority_99 = split_ratio_for_ag_news(balanced_data, 'business', majority_count=980, minority_count=20)\n",
        "\n",
        "# Keep original balanced_data as the balanced dataset\n",
        "# Testing\n",
        "balanced_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3b27bc",
      "metadata": {},
      "source": [
        "Load toxic text dataset (The dataset is already imbalanced)\n",
        "\n",
        "- Rename the columns to have the same names as other datasets\n",
        "- Label = 0 --> Not toxic\n",
        "- Label = 1 --> Toxic\n",
        "- Map label column into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "afb89ef6",
      "metadata": {},
      "outputs": [],
      "source": [
        "toxic_label_map = {\n",
        "    0: \"nontoxic\",\n",
        "    1: \"toxic\"\n",
        "}\n",
        "\n",
        "def split_ratio_for_toxic_dataset(df, majority_label='nontoxic', majority_count=500, minority_count=20):\n",
        "    \"\"\"Create an imbalanced toxic_text subset where `majority_label` has `majority_count` samples and the other label has `minority_count`.\"\"\"\n",
        "    parts = []\n",
        "    for lab in df['label'].unique():\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "toxic_text = pd.read_csv(\"../Data/toxic_text/train.csv\")\n",
        "toxic_text = toxic_text[[\"comment_text\", \"toxic\"]]\n",
        "toxic_text = toxic_text.rename(columns={\"comment_text\": \"text\", \"toxic\": \"label\"})\n",
        "toxic_text[\"label\"] = toxic_text[\"label\"].map(toxic_label_map)\n",
        "\n",
        "# Get 3 small subsets of the main datasets with 3 different ratios and different majority classes\n",
        "toxic_balanced = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=500, minority_count=500)\n",
        "# Increase minority_count to 20 as requested\n",
        "toxic_99_to_1 = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=980, minority_count=20)\n",
        "toxic_49_to_1 = split_ratio_for_toxic_dataset(toxic_text, majority_label='nontoxic', majority_count=940, minority_count=20)\n",
        "toxic_toxic_majority_99 = split_ratio_for_toxic_dataset(toxic_text, majority_label='toxic', majority_count=980, minority_count=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c04be3d",
      "metadata": {},
      "source": [
        "Load twitter emotion type dataset (This is also imbalanced)\n",
        "- Create 3 small datasets, roughly 2000 rows each, with balanced, 99:1, 49:1 imbalanced ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6b360aa1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "sadness     950\n",
              "surprise     20\n",
              "love         20\n",
              "fear         20\n",
              "anger        20\n",
              "joy          20\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotion_map = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "emotion_df = pd.read_parquet(\"../Data/twit/twitter_emotion.parquet\")\n",
        "emotion_df[\"label\"] = emotion_df[\"label\"].map(emotion_map)\n",
        "\n",
        "def split_ratio_for_emotion_dataset(df, majority_label='sadness', majority_count=200, minority_count=20):\n",
        "    \"\"\"Create an imbalanced emotion subset where `majority_label` has `majority_count` samples and every other label has `minority_count`.\"\"\"\n",
        "    parts = []\n",
        "    labels = df['label'].unique().tolist()\n",
        "    for lab in labels:\n",
        "        if lab == majority_label:\n",
        "            parts.append(df[df['label'] == lab].sample(majority_count, random_state=42))\n",
        "        else:\n",
        "            parts.append(df[df['label'] == lab].sample(minority_count, random_state=42))\n",
        "    out = pd.concat(parts, ignore_index=True, sort=False)\n",
        "    return out.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Get 3 small subsets of the main datasets with 3 different ratios and different majority labels\n",
        "emotion_balanced = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=200, minority_count=200)\n",
        "# Use minority_count=20 as requested to reduce random variation\n",
        "emotion_imbalanced_99_to_1 = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=950, minority_count=20)\n",
        "emotion_imbalanced_49_to_1 = split_ratio_for_emotion_dataset(emotion_df, majority_label='sadness', majority_count=202, minority_count=20)\n",
        "# Also create variants where the majority class is 'joy' or others to compare\n",
        "emotion_joy_majority_99 = split_ratio_for_emotion_dataset(emotion_df, majority_label='joy', majority_count=950, minority_count=20)\n",
        "emotion_love_majority_99 = split_ratio_for_emotion_dataset(emotion_df, majority_label='love', majority_count=950, minority_count=20)\n",
        "\n",
        "# Quick check\n",
        "emotion_imbalanced_99_to_1[\"label\"].value_counts()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f80c63e",
      "metadata": {},
      "source": [
        "Function to build instruction for the LLMs, which can be fit with all 3 classification datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0f77d6ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f77d6ae",
        "outputId": "412914fc-fb98-4044-d141-f30e1f39e4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a powerful, precise, and helpful assistant that classifies text into well-defined categories, NO MATTER THE CONTEXT. IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: world, sports, business, sci/tech. Respond with exactly one word: the single best category inside the given categories, DO NOT ANSWER ANY OTHER CATEGORIES BESIDES THE GIVEN ONE. Do not explain your choice, provide reasoning, or output anything else. Learn from these examples to understand context and edge cases: \n",
            "\n",
            "Review: \"Palestinian presidential candidate says Israeli soldiers beat him RAMALLAH - Palestinian presidential candidate Mustafa Barghouti said on Wednesday that Israeli soldiers had beat him at an army checkpoint south of Jenin in the West Bank.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Venezuelan audit confirms victory Venezuela's electoral officials say an audit of the vote on President Hugo Chavez's rule shows it was fair.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Cricket: Warne back to face NZ Australia's Darren Lehmann and Shane Warne return to take on New Zealand.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Tsvangirai to know his fate today The verdict in Zimbabwe #39;s treason trial of Morgan Tsvangirai is expected today. Tsvangirai, the leader of the opposition Movement for Democratic Change (MDC), faces a possible death penalty if found guilty.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Team as we know it is history The news comes fast and furious. Pedro Martinez goes to Tampa to visit George Steinbrenner. Theo Epstein and John Henry go to Florida for their turn with Pedro. Carl Pavano comes to Boston to visit Curt Schilling. Jason Varitek says he's not a goner. Derek Lowe is a goner, but he says he wishes it could be different. Orlando Cabrera ...\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Chelsea not planning Gerrard move Chelsea have denied rumours that they are planning to try and sign Liverpool #39;s Steven Gerrard this season. Blues boss Jose Mourinho insisted that there would be no big-money bid for the England midfield star when the transfer window opens on 1 January.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"It's about the best you can do with BCS Playoffs? Who needs playoffs? And isn't that ironic in another season when the \"P-word\" was again front and center in a Bowl Championship Series controversy?\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Wilfork has a nose for his new position Vince Wilfork came to the Patriots this offseason as a defensive lineman, meaning that in college he was accustomed to working his way to the opponent's backfield when the ball was snapped. But New England's first-round draft pick is now playing nose tackle, which means he must stay put and keep a crease from forming in the middle.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"US economic barometer down 0.3 in third straight decline WASHINGTON : A closely watched index of future economic activity fell 0.3 percent in August, the third consecutive monthly decline, the Conference Board said on Thursday.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Harmony Grabs Hold of Gold Fields HARMONY is set to become the world #39;s biggest gold producing mining company in just four months. This week Harmony moved closer to successfully concluding its hostile bid for rival Gold Fields.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Nigeria centre stage as oil traders eye new highs High-flying oil prices could set new records this week if rebels disrupt the flow of crude from Nigeria, and are unlikely to fall far even if tensions there ease given global supply strains, according to analysts.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Tough Quarter for Circuit City Circuit City (CC:NYSE - news - research) Monday said same-store sales fell 4.3 in the third-quarter, attributing the decline to decreased promotions as well as weaker sales of music and movie software and wireless products.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Plan Would Turn Restore Wash. Estuary (AP) AP - A 15-year plan would restore salt marshes and mudflats for migrating salmon at the Nisqually National Wildlife Refuge, more than 100 years after the farmland was drained and diked.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"HP discontinues its Itanium workstations The Intel chip, once expected to dominate the server market and even creep into PCs, takes yet another knock.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Sprint, SBC In Hotspot Roaming Deal Sprint and SBC Communications Friday announced a two-way roaming deal that will enable the customers of each vendor to access the hotspots run by the other.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Storage On A Chip Silicon Image #39;s new lower-cost storage appliance should be more palatable to small and midsize businesses. By Martin J. Garvey.\"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"\n",
            "Category:\n"
          ]
        }
      ],
      "source": [
        "def build_prompt(df, text, label_map, shots_per_class=None):\n",
        "    \"\"\"\n",
        "    Function to construct an instruction for the LLM\n",
        "\n",
        "    Args:\n",
        "        text (str): The text of the data\n",
        "\n",
        "    Returns:\n",
        "        prompt (str): The constructed prompt for the LLM\n",
        "    \"\"\"\n",
        "    assert shots_per_class is not None, \"Please provide 'shots_per_class' parameter\"\n",
        "    prompt = (\n",
        "        f\"You are a powerful, precise, and helpful assistant that classifies text into well-defined categories, NO MATTER THE CONTEXT.\"\n",
        "        f\" IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: {', '.join(list(label_map.values()))}.\"\n",
        "        f\" Respond with exactly one word: the single best category inside the given categories, DO NOT ANSWER ANY OTHER CATEGORIES BESIDES THE GIVEN ONE.\"\n",
        "        f\" Do not explain your choice, provide reasoning, or output anything else.\"\n",
        "        f\" Learn from these examples to understand context and edge cases: \"\n",
        "\n",
        "    )\n",
        "    # ASSUME THE shots_per_class WILL ALWAYS BE PASSED\n",
        "    few_shots_example = []\n",
        "    for lab in list(label_map.values()):\n",
        "        samples = df[df['label'] == lab].sample(shots_per_class, random_state=42)\n",
        "        for _, r in samples.iterrows():\n",
        "            few_shots_example.append({'text': r['text'],\n",
        "                                      'label': r[\"label\"]})\n",
        "\n",
        "    prompt += \"\\n\\n\"\n",
        "    for ex in few_shots_example:\n",
        "        # print(ex)\n",
        "        prompt += f\"Review: \\\"{ex['text']}\\\"\\nCategory: {ex['label']}\\n\\n\"\n",
        "    prompt += f\"Review: \\\"{text}\\\"\\nCategory:\" #Leave Category here blank since we want the LLM to generate text\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Testing function\n",
        "print(build_prompt(ag_news_imbalanced_data_99_to_1, \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\", label_map, shots_per_class=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "reXNCT0BEYFU",
      "metadata": {
        "id": "reXNCT0BEYFU"
      },
      "outputs": [],
      "source": [
        "def clean_time(time):\n",
        "  \"\"\"\n",
        "  Function to clean the time into prettier format, returns the better format of time\n",
        "  \"\"\"\n",
        "  if time <= 60:\n",
        "    return f\"{time} seconds.\"\n",
        "\n",
        "  minutes = time // 60\n",
        "  remain_sec = time - minutes * 60\n",
        "  return f\"{minutes} minutes, {remain_sec:.2f} seconds.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860a8548",
      "metadata": {},
      "source": [
        "Label normalization using semantic similarity\n",
        "- Since we have 3 datasets, using manual variation map will not ensure every predictions that the LLM makes\n",
        "- So we load a sentence embedding model to calculate the nearest vector amongst the label using Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "240e9e2d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sadness\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Testing with AG News\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Ag news\n",
        "valid_labs_ag_news = list(label_map.values())\n",
        "valid_embeddings_ag_news = embedding_model.encode(valid_labs_ag_news, convert_to_tensor=True)\n",
        "\n",
        "# Toxic Text\n",
        "valid_labs_toxic_text = list(toxic_label_map.values())\n",
        "valid_embeddings_toxic_text = embedding_model.encode(valid_labs_toxic_text, convert_to_tensor=True)\n",
        "\n",
        "# Twitter Emotion\n",
        "valid_labs_emotion = list(emotion_map.values())\n",
        "valid_embeddings_emotion = embedding_model.encode(valid_labs_emotion, convert_to_tensor=True)\n",
        "\n",
        "def normalize(label, valid_embeddings, valid_labs):\n",
        "    pred_emb = embedding_model.encode(label, convert_to_tensor=True)\n",
        "    cos_scores = util.cos_sim(pred_emb, valid_embeddings)[0]\n",
        "    closest_idx = cos_scores.argmax().item()\n",
        "    return valid_labs[closest_idx]\n",
        "\n",
        "# Testing for AG News\n",
        "raw_preds = \"I am so sad\"\n",
        "normalized_preds = normalize(raw_preds, valid_embeddings=valid_embeddings_emotion, valid_labs=valid_labs_emotion)\n",
        "print(normalized_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9249686c",
      "metadata": {
        "id": "9249686c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import pipeline, logging\n",
        "from time import time\n",
        "\n",
        "\n",
        "# Load model\n",
        "\n",
        "\n",
        "# CREATE A FUNCTION TO RUN CLASSFICATION\n",
        "def classify(model, df, label_map, shots, batch_size=16, max_new_tokens=3, valid_embeddings=None, valid_labs=None):\n",
        "    \"\"\"\n",
        "    Function to run classification with different number of shots\n",
        "\n",
        "    Args:\n",
        "        model (str): name of the model\n",
        "        tokenizer\n",
        "        df (pd.DataFrame): the pandas dataframe\n",
        "        batch_size (int): batch size per run\n",
        "\n",
        "    Returns:\n",
        "        pred_arr (List[str]): the array that contains all predictions\n",
        "    \"\"\"\n",
        "    # Initiate a pipeline for each dataset\n",
        "    # USE text2text-generation for the gemma model\n",
        "    # USE text-generation for the others, or text-classification\n",
        "    # USE fill-mask for distillbert\n",
        "    pipe = pipeline(\"text-generation\", model=model, dtype=torch.float16)\n",
        "    logging.set_verbosity_error()\n",
        "\n",
        "    # Generate prompts for all rows\n",
        "    prompts = [build_prompt(df, text, label_map, shots_per_class=shots) for text in df[\"text\"]]\n",
        "\n",
        "    # Run the pipeline for each row\n",
        "    pred_arr = []\n",
        "    start_time = time()\n",
        "\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = prompts[i:i + batch_size] #slices a sublist of prompts\n",
        "        results = pipe(batch, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "        for prompt, res in zip(batch, results):\n",
        "            pred = res[0]['generated_text'][len(prompt):].strip().lower().split()\n",
        "            # print(f\"Real value: {df[\"label\"]}\")\n",
        "            # print(f\"Predicted value: {pred}\")\n",
        "            if pred[0] not in list(label_map.values()):\n",
        "                normalized_pred = normalize(pred[0], valid_embeddings=valid_embeddings, valid_labs=valid_labs)\n",
        "                pred_arr.append(normalized_pred)\n",
        "            else:\n",
        "                pred_arr.append(pred[0]) #Use pred[0] for some cases\n",
        "    end_time = time()\n",
        "\n",
        "    total_time = clean_time(end_time - start_time)\n",
        "\n",
        "    print(\"Total running time is \" + total_time)\n",
        "    return pred_arr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f87464c",
      "metadata": {},
      "source": [
        "Function to compute all metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "75345a5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pass list(df[\"text\"]) for y_true\n",
        "# list(label_map.values())\n",
        "\n",
        "def eval_llm(y_true, y_pred, label_map):\n",
        "    y_true_arr = np.array([x.lower().strip() for x in y_true])\n",
        "    # print(y_pred)  # avoid noisy output\n",
        "    y_pred_arr = np.array([x.lower().strip() for x in y_pred])\n",
        "\n",
        "    labels = [lab.lower() for lab in list(label_map.values())]\n",
        "\n",
        "    # Calculate macro scores:\n",
        "    macro_f1 = f1_score(y_true_arr, y_pred_arr, labels=labels, zero_division=0, average='macro')\n",
        "    macro_recall = recall_score(y_true_arr, y_pred_arr, labels=labels, average='macro', zero_division=0)\n",
        "    bal_acc = balanced_accuracy_score(y_true_arr, y_pred_arr)\n",
        "    mcc = matthews_corrcoef(y_true_arr, y_pred_arr)\n",
        "\n",
        "    # Calculate per-class precision, recall, f1 (returns arrays aligned with labels)\n",
        "    precision_per_class_vals = precision_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "    recall_per_class_vals = recall_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "    f1_per_class_vals = f1_score(y_true_arr, y_pred_arr, labels=labels, average=None, zero_division=0)\n",
        "\n",
        "    precision_per_class = {}\n",
        "    recall_per_class = {}\n",
        "    f1_per_class = {}\n",
        "    for idx, cls in enumerate(labels):\n",
        "        precision_per_class[cls] = float(precision_per_class_vals[idx])\n",
        "        recall_per_class[cls] = float(recall_per_class_vals[idx])\n",
        "        f1_per_class[cls] = float(f1_per_class_vals[idx])\n",
        "\n",
        "    # Calculate AUPRC per class\n",
        "    y_true_bin = label_binarize(y_true_arr, classes=labels)\n",
        "    y_pred_bin = label_binarize(y_pred_arr, classes=labels)\n",
        "    if len(labels) == 2 and y_true_bin.shape[1] == 1:\n",
        "        y_true_bin = np.hstack([1 - y_true_bin, y_true_bin])\n",
        "        y_pred_bin = np.hstack([1 - y_pred_bin, y_pred_bin])\n",
        "\n",
        "    auprc_per_class = {}\n",
        "    for idx, cls in enumerate(labels):\n",
        "        ap = average_precision_score(y_true_bin[:, idx], y_pred_bin[:, idx])\n",
        "        auprc_per_class[cls] = float(ap)\n",
        "\n",
        "    return {\n",
        "        \"macro_f1\": float(macro_f1),\n",
        "        \"macro_recall\": float(macro_recall),\n",
        "        \"balanced_accuracy\": float(bal_acc),\n",
        "        \"mcc\": float(mcc),\n",
        "        \"auprc_per_class\": auprc_per_class,\n",
        "        \"precision_per_class\": precision_per_class,\n",
        "        \"recall_per_class\": recall_per_class,\n",
        "        \"f1_per_class\": f1_per_class\n",
        "    }\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875bcf38",
      "metadata": {},
      "source": [
        "NOW FOCUSING ON QWEN2.5 INSTRUCT MODEDLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "eb1247a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1247a0",
        "outputId": "bb995908-9dff-4b54-ee56-911de09e93c9"
      },
      "outputs": [],
      "source": [
        "# model, df, label_map, shots, batch_size=8, max_new_tokens=3\n",
        "def run_experiments(model, datasets_dict, dataset_name, label_map, shots_list=[2,4,8], batch_size=16, valid_embeddings=None, valid_labs=None):\n",
        "    import os\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    import numpy as _np\n",
        "    import pandas as _pd\n",
        "\n",
        "    def infer_meta(ds_name, df):\n",
        "        # Try to infer ratio and majority label from the dataset name using heuristics\n",
        "        ratio = 'unknown'\n",
        "        maj_label = 'unknown'\n",
        "\n",
        "        # Check common name patterns\n",
        "        if 'balanced' in ds_name:\n",
        "            ratio = 'balanced'\n",
        "        m = re.search(r\"(\\d+)_to_(\\d+)\", ds_name)\n",
        "        if m:\n",
        "            ratio = f\"{m.group(1)}:{m.group(2)}\"\n",
        "\n",
        "        # look for \"_majority_\" pattern like 'world_majority_99'\n",
        "        m2 = re.search(r\"([A-Za-z0-9]+)_majority\", ds_name)\n",
        "        if m2:\n",
        "            maj_label = m2.group(1)\n",
        "\n",
        "        # fallback: infer from df counts\n",
        "        try:\n",
        "            counts = df['label'].value_counts()\n",
        "            if len(counts) > 0:\n",
        "                maj_label_from_df = counts.idxmax()\n",
        "                if maj_label == 'unknown':\n",
        "                    maj_label = str(maj_label_from_df)\n",
        "                # compute numeric ratio using most common and the minimum of others\n",
        "                maj_count = int(counts.max())\n",
        "                others = counts.drop(maj_label_from_df)\n",
        "                if len(others) > 0:\n",
        "                    min_count = int(others.min())\n",
        "                else:\n",
        "                    min_count = 0\n",
        "                ratio = f\"{maj_count}:{min_count}\"\n",
        "        except Exception:\n",
        "            # keep heuristics result\n",
        "            pass\n",
        "\n",
        "        return ratio, maj_label\n",
        "\n",
        "    results = []\n",
        "    # Ensure results folder exists for this dataset\n",
        "    out_dir = os.path.join(\"../results\", dataset_name)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ds_name, df in datasets_dict.items():\n",
        "        print(f\"=== RUNNING DATASET {ds_name} ===\")\n",
        "        test_df = df.sample(frac=1).reset_index(drop=True)\n",
        "        for shots in shots_list:\n",
        "            print(f\"    === SHOTS = {shots} ===\")\n",
        "            preds = classify(model, test_df, label_map, shots=shots, batch_size=batch_size, valid_embeddings=valid_embeddings, valid_labs=valid_labs)\n",
        "            metrics = eval_llm(test_df['label'].tolist(), preds, label_map=label_map)\n",
        "\n",
        "            # infer dataset metadata\n",
        "            ratio, maj_label = infer_meta(ds_name, df)\n",
        "\n",
        "            row = {\n",
        "                \"model\": model,\n",
        "                \"dataset\": ds_name,\n",
        "                \"shots\": shots,\n",
        "                \"dataset_ratio\": ratio,\n",
        "                \"majority_label\": maj_label,\n",
        "                **metrics\n",
        "            }\n",
        "            results.append(row)\n",
        "\n",
        "            # Create a flattened aggregated DataFrame for better CSV readability\n",
        "            df_agg = _pd.json_normalize(results)\n",
        "            # replace dots in column names (from nested dicts) with underscores\n",
        "            df_agg.columns = [c.replace('.', '_') for c in df_agg.columns]\n",
        "\n",
        "\n",
        "            agg_name = f\"few_shot_results_{model.replace('/','_')}.csv\"\n",
        "            agg_path = os.path.join(out_dir, agg_name)\n",
        "            df_agg.to_csv(agg_path, index=False)\n",
        "\n",
        "            # New per-params file: group by (model, ds_name, ratio, maj_label, shots)\n",
        "            safe_model = model.replace('/', '_')\n",
        "            safe_ds_name = ds_name.replace(' ', '_')\n",
        "            safe_maj = str(maj_label).replace(' ', '_').replace('/', '_')\n",
        "            ratio_safe = str(ratio).replace(':', '-')\n",
        "            params_fname = f\"results__{safe_model}__{safe_ds_name}__ratio-{ratio_safe}__majority-{safe_maj}__shots-{shots}.csv\"\n",
        "            params_path = os.path.join(out_dir, params_fname)\n",
        "\n",
        "            # Flatten the current row and append to the per-params CSV (create if not exists)\n",
        "            flat_row_df = _pd.json_normalize([row])\n",
        "            flat_row_df.columns = [c.replace('.', '_') for c in flat_row_df.columns]\n",
        "\n",
        "            if _pd.io.common.file_exists(params_path):\n",
        "                # append without header\n",
        "                flat_row_df.to_csv(params_path, mode='a', header=False, index=False)\n",
        "            else:\n",
        "                flat_row_df.to_csv(params_path, index=False)\n",
        "\n",
        "    return _pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Y_Ligz6iBlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ligz6iBlf7",
        "outputId": "3563a9ba-7a5d-4af5-c1fa-0db052027417"
      },
      "outputs": [],
      "source": [
        "# Create a dataset dict for easy mapping\n",
        "\n",
        "ag_news_datasets_dict = {\n",
        "    \"ag_news_balanced\": balanced_data,\n",
        "    \"ag_news_imbalanced_data_99_to_1\": ag_news_imbalanced_data_99_to_1,\n",
        "    \"ag_news_imbalanced_data_49_to_1\": ag_news_imbalanced_data_49_to_1,\n",
        "    # Variants where a specific class is the majority (minority_count=20)\n",
        "    \"ag_news_world_majority_99\": ag_news_world_majority_99,\n",
        "    \"ag_news_sports_majority_99\": ag_news_sports_majority_99,\n",
        "    \"ag_news_business_majority_99\": ag_news_business_majority_99\n",
        "}\n",
        "\n",
        "toxic_datasets_dict = {\n",
        "    \"toxic_text\": toxic_balanced,\n",
        "    \"toxic_99_to_1\": toxic_99_to_1,\n",
        "    \"toxic_49_to_1\": toxic_49_to_1,\n",
        "    \"toxic_toxic_majority_99\": toxic_toxic_majority_99\n",
        "}\n",
        "\n",
        "emotion_datasets_dict = {\n",
        "    \"emotion_df\": emotion_balanced,\n",
        "    \"emotion_imbalanced_99_to_1\": emotion_imbalanced_99_to_1,\n",
        "    \"emotion_imbalanced_49_to_1\": emotion_imbalanced_49_to_1,\n",
        "    \"emotion_joy_majority_99\": emotion_joy_majority_99,\n",
        "    \"emotion_love_majority_99\": emotion_love_majority_99\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05c9ba5",
      "metadata": {},
      "source": [
        "Run models + evals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7023ccac",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"Qwen/Qwen2.5-1.5B-Instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1457c6",
      "metadata": {},
      "source": [
        "Quantize model (Optional)\n",
        "- Use subprocess library to run shell script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8b02dc47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /Volumes/huysuy05/Projects/Bias_of_LLMs/src\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "script_path = Path(\"../scripts/convert.py\")\n",
        "print(\"cwd:\", Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f26f8745",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STDOUT:  [INFO] Loading\n",
            "\n",
            "STDERR:  \n",
            "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]\n",
            "Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 115971.54it/s]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "cmd = [\"python\", str(script_path), \"--hf-path\", model]\n",
        "\n",
        "try:\n",
        "    res = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"STDOUT: \", res.stdout)\n",
        "    print(\"STDERR: \", res.stderr)\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Script failed with error: {e}\")\n",
        "    print(\"STDOUT:\", e.stdout)\n",
        "    print(\"STDERR:\", e.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dd1587a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RUNNING DATASET ag_news_balanced ===\n",
            "    === SHOTS = 2 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running time is 53.0 minutes, 12.11 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 108.0 minutes, 16.84 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 175.0 minutes, 31.83 seconds.\n",
            "=== RUNNING DATASET ag_news_imbalanced_data_99_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 50.0 minutes, 54.72 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 88.0 minutes, 50.87 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 172.0 minutes, 31.44 seconds.\n",
            "=== RUNNING DATASET ag_news_imbalanced_data_49_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 51.0 minutes, 22.33 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 83.0 minutes, 11.70 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 166.0 minutes, 24.27 seconds.\n",
            "=== RUNNING DATASET ag_news_world_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 12.0 minutes, 46.20 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 21.0 minutes, 14.14 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 42.0 minutes, 14.97 seconds.\n",
            "=== RUNNING DATASET ag_news_sports_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 12.0 minutes, 30.00 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 21.0 minutes, 15.09 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 47.0 minutes, 1.66 seconds.\n",
            "=== RUNNING DATASET ag_news_business_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 15.0 minutes, 19.78 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 21.0 minutes, 15.42 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 47.0 minutes, 20.82 seconds.\n"
          ]
        }
      ],
      "source": [
        "# RUN AG NEWS DATASET\n",
        "\n",
        "res_df = run_experiments(model, ag_news_datasets_dict, 'ag_news',label_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_ag_news, valid_labs=valid_labs_ag_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bab41c3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RUNNING DATASET toxic_text ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 9.0 minutes, 14.32 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 13.0 minutes, 1.13 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 33.0 minutes, 2.55 seconds.\n",
            "=== RUNNING DATASET toxic_99_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 8.0 minutes, 54.68 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 12.0 minutes, 45.15 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 24.0 minutes, 40.23 seconds.\n",
            "=== RUNNING DATASET toxic_49_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 10.0 minutes, 4.93 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 13.0 minutes, 34.58 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 21.0 minutes, 45.98 seconds.\n",
            "=== RUNNING DATASET toxic_toxic_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 7.0 minutes, 58.94 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 11.0 minutes, 10.08 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 18.0 minutes, 50.63 seconds.\n"
          ]
        }
      ],
      "source": [
        "# RUN TOXIC TEXT DATASET\n",
        "res_df = run_experiments(model, toxic_datasets_dict, \"toxic_text\",toxic_label_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_toxic_text, valid_labs=valid_labs_toxic_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b524933f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RUNNING DATASET emotion_df ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 10.0 minutes, 23.07 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 17.0 minutes, 16.30 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 33.0 minutes, 43.33 seconds.\n",
            "=== RUNNING DATASET emotion_imbalanced_99_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 10.0 minutes, 13.38 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 16.0 minutes, 34.54 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 32.0 minutes, 17.18 seconds.\n",
            "=== RUNNING DATASET emotion_imbalanced_49_to_1 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 3.0 minutes, 0.20 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 5.0 minutes, 5.81 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 9.0 minutes, 8.05 seconds.\n",
            "=== RUNNING DATASET emotion_joy_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 9.0 minutes, 17.13 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 16.0 minutes, 41.30 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 30.0 minutes, 10.16 seconds.\n",
            "=== RUNNING DATASET emotion_love_majority_99 ===\n",
            "    === SHOTS = 2 ===\n",
            "Total running time is 9.0 minutes, 25.91 seconds.\n",
            "    === SHOTS = 4 ===\n",
            "Total running time is 15.0 minutes, 56.99 seconds.\n",
            "    === SHOTS = 8 ===\n",
            "Total running time is 30.0 minutes, 53.35 seconds.\n"
          ]
        }
      ],
      "source": [
        "# RUN TWITTER EMOTION DATASET\n",
        "res_df = run_experiments(model, emotion_datasets_dict, 'twitter_emotion', emotion_map, shots_list=[2,4,8], valid_embeddings=valid_embeddings_emotion, valid_labs=valid_labs_emotion)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

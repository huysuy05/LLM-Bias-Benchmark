{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (2025.10.5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install huggingface_hub\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpython\u001b[49m-dotenv\n\u001b[32m      3\u001b[39m scikit-learn\n\u001b[32m      4\u001b[39m torch\n",
      "\u001b[31mNameError\u001b[39m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7445c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Fears for T N pension after talks Unions repre...      2\n",
       "1  The Race is On: Second Private Team Sets Launc...      3\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get training dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "df_train.head()\n",
    "\n",
    "# Get testing dataset\n",
    "df_test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5801d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Training Set Label Distribution:\n",
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalanced Training Set Label Distribution:\n",
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Sample out an balanced training data\n",
    "n_rows_per_class = 1000\n",
    "balanced_dfs = []\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique()):\n",
    "    class_samples = df_train[df_train[\"label\"] == label]\n",
    "    balanced_dfs.append(class_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "balanced_data = pd.concat(balanced_dfs)\n",
    "\n",
    "# Sample out an imbalanced training data (Assume label 0 as the majority class)\n",
    "n_majority = 1000\n",
    "n_minority = 1000\n",
    "\n",
    "n_majority_1 = 1000\n",
    "n_minority_1 = 1000\n",
    "\n",
    "imbalanced_dfs = []\n",
    "imbalanced_dfs_1 = []\n",
    "\n",
    "label_0_class = df_train[df_train[\"label\"] == 2] #We pick class 0 as the majority class\n",
    "imbalanced_dfs.append(label_0_class.sample(n_majority, random_state=42))\n",
    "imbalanced_dfs_1.append(label_0_class.sample(n_majority_1, random_state=42))\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique()):\n",
    "    if label != 2:\n",
    "        class_samples = df_train[df_train['label'] == label]\n",
    "        imbalanced_dfs.append(class_samples.sample(n_minority, random_state=42))\n",
    "        imbalanced_dfs_1.append(class_samples.sample(n_minority_1, random_state=42))\n",
    "\n",
    "imbalanced_data = pd.concat(imbalanced_dfs)\n",
    "# Shuffle the imbalanced dataset to mix the classes\n",
    "imbalanced_data = imbalanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "imbalanced_data_5_1_ratio = pd.concat(imbalanced_dfs_1)\n",
    "imbalanced_data_5_1_ratio = imbalanced_data_5_1_ratio.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Training Set Label Distribution:\")\n",
    "print(balanced_data['label'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nImbalanced Training Set Label Distribution:\")\n",
    "print(imbalanced_data['label'].value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654b1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small testing set\n",
    "n_rows_per_class = 1000\n",
    "test_balanced_dfs = []\n",
    "for label in sorted(df_test[\"label\"].unique()):\n",
    "    test_samples = df_test[df_test[\"label\"] == label]\n",
    "    test_balanced_dfs.append(test_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "testing_set = pd.concat(test_balanced_dfs)\n",
    "testing_set = testing_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5017f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Data/ag_news'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save datasets to parquet for later use\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbalanced_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData/ag_news/ag_news_train_balanced.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m imbalanced_data.to_parquet(\u001b[33m'\u001b[39m\u001b[33mData/ag_news/ag_news_train_imbalanced_99_to_1.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m testing_set.to_parquet(\u001b[33m'\u001b[39m\u001b[33mData/ag_news/ag_news_test_small.parquet\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:199\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m     merged_metadata = {**existing_metadata, **df_metadata}\n\u001b[32m    197\u001b[39m     table = table.replace_schema_metadata(merged_metadata)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    207\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(path_or_handle, io.BufferedWriter)\n\u001b[32m    208\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path_or_handle, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    209\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle.name, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle.name, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'Data/ag_news'"
     ]
    }
   ],
   "source": [
    "# Save datasets to parquet for later use\n",
    "balanced_data.to_parquet('../Data/ag_news/ag_news_train_balanced.parquet')\n",
    "imbalanced_data.to_parquet('../Data/ag_news/ag_news_train_imbalanced_99_to_1.parquet')\n",
    "testing_set.to_parquet('../Data/ag_news/ag_news_test_small.parquet')\n",
    "imbalanced_data_5_1_ratio.to_parquet('../Data/ag_news/ag_news_train_imbalanced_49_to_1_ratio.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c33036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to build the prompt strings on both balanced and imbalanced\n",
    "label_map = {\n",
    "    0: \"world\",\n",
    "    1: \"sports\",\n",
    "    2: \"business\",\n",
    "    3: \"sci/Tech\"\n",
    "}\n",
    "\n",
    "def build_shots_prompt(train_df, shots=None, imbalanced_ratio=None):\n",
    "    prompt_lines = [\"\"\"You are a strict text classification system.\n",
    "\n",
    "                        Task:\n",
    "                        Classify the text into exactly one of these categories:\n",
    "                        - world\n",
    "                        - sports\n",
    "                        - business\n",
    "                        - sci/tech\n",
    "\n",
    "                        Rules:\n",
    "                        1. Output only one label.\n",
    "                        2. The label must be exactly one of: world, sports, business, sci/tech.\n",
    "                        3. The label must be lowercase.\n",
    "                        4. Do not output explanations, punctuation, or extra text.\"\"\"]\n",
    "    \n",
    "    if shots:\n",
    "        # Build a balanced prompt\n",
    "        for label in sorted(train_df['label'].unique()):\n",
    "            class_samples = train_df[train_df['label'] == label].sample(shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "                \n",
    "    elif imbalanced_ratio:\n",
    "        # Build an imbalanced prompt based on the provided ratios\n",
    "        for label, n_shots in imbalanced_ratio.items():\n",
    "            class_samples = train_df[train_df['label'] == label].sample(n_shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "    else:\n",
    "        raise ValueError(\"Must provide either 'shots_per_class' or 'imbalanced_ratios'\")\n",
    "        \n",
    "    # Join all lines into a single string\n",
    "    prompt_str = \"\\n\".join(prompt_lines)\n",
    "    return prompt_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0ef34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, examples_prompt, model_name, api_key):\n",
    "    full_prompt = f\"{examples_prompt}\\n\\nNow classify this new text:\\nText: {text}\\nCategory:\"\n",
    "    payload = {\n",
    "        \"model\": model_name, \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0,  \n",
    "        \"max_tokens\": 1    \n",
    "    }\n",
    "\n",
    "    # The headers required by Open Router\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            data=json.dumps(payload)\n",
    "        )\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        result = response.json()\n",
    "        # Extract the model's response, which is similar to the OpenAI API.\n",
    "        prediction = result['choices'][0]['message']['content'].strip()\n",
    "        pred_lines = prediction.splitlines()[0].lower()\n",
    "        for label in label_map.values():\n",
    "            if label.lower() in pred_lines:\n",
    "                return label\n",
    "        return prediction.strip()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for text '{text[:50]}...': {e}\")\n",
    "        time.sleep(5)  \n",
    "        return \"Error\"\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not parse response for text '{text[:50]}...': {e}. Response: {result}\")\n",
    "        return \"Error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5e21680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EVALUATING nvidia/nemotron-nano-9b-v2:free ---\n",
      "Running with Balanced prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='world', Cleaned='world'\n",
      "\n",
      "=== Balanced Accuracy: 80.0000 ===\n",
      "\n",
      "Running with Imbalanced with 10:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 10:1 Ratio Accuracy: 85.0000 ===\n",
      "\n",
      "Running with Imbalanced with 5:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 5:1 Ratio Accuracy: 80.0000 ===\n",
      "\n",
      "Evaluation done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "model = \"nvidia/nemotron-nano-9b-v2:free\"\n",
    "\n",
    "# Define expected labels to map into the LLM's response\n",
    "expected_labels = list(label_map.values())\n",
    "expected_labels = [lab.lower() for lab in expected_labels]\n",
    "\n",
    "balanced_prompt = build_shots_prompt(balanced_data, shots=2)\n",
    "imbalanced_prompt = build_shots_prompt(balanced_data, imbalanced_ratio={0: 10, 1: 10, 2: 1, 3: 1})\n",
    "imbalanced_prompt_5_to_1 = build_shots_prompt(balanced_data, imbalanced_ratio={0:5, 1:5, 2:1, 3:1})\n",
    "\n",
    "print(f\"--- EVALUATING {model} ---\")\n",
    "model_res = {}\n",
    "\n",
    "def clean_prediction(pred, expected_labels):\n",
    "    if not pred:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Convert to lowercase and remove extra spaces\n",
    "    pred = pred.lower().strip()\n",
    "    \n",
    "    \n",
    "    pred = re.sub(r'[^\\w\\s]', '', pred)  \n",
    "    pred = re.sub(r'\\b(category|is|the|a|an)\\b', '', pred)  \n",
    "    pred = pred.strip()\n",
    "    \n",
    "    \n",
    "    for label in expected_labels:\n",
    "        if label.lower() in pred or pred in label.lower():\n",
    "            return label\n",
    "    \n",
    "   \n",
    "    variation_map = {\n",
    "        'sport': 'Sports',\n",
    "        'sci': 'Sci/Tech',\n",
    "        'technology': 'Sci/Tech',\n",
    "        'tech': 'Sci/Tech',\n",
    "        'businesses': 'Business',\n",
    "        'world news': 'World'\n",
    "    }\n",
    "    \n",
    "    for variation, correct_label in variation_map.items():\n",
    "        if variation in pred:\n",
    "            return correct_label.lower()\n",
    "    \n",
    "    \n",
    "    print(f\"Unrecognized prediction: '{pred}' -> Mapping to 'Unknown'\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "accuracy_arr = []\n",
    "for prompt_name, prompt in [(\"Balanced\", balanced_prompt), (\"Imbalanced with 10:1 Ratio\", imbalanced_prompt), (\"Imbalanced with 5:1 Ratio\", imbalanced_prompt_5_to_1)]:\n",
    "    print(f\"Running with {prompt_name} prompt\\n\")\n",
    "    \n",
    "    curr_pred = 0\n",
    "    n_rows = 20\n",
    "\n",
    "    for _, row in testing_set.iloc[n_rows:41].iterrows():\n",
    "        y_true = label_map[row[\"label\"]].lower()\n",
    "        raw_pred = classify(\n",
    "            text=row[\"text\"],\n",
    "            examples_prompt=prompt,\n",
    "            model_name=model,\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        \n",
    "       \n",
    "        cleaned_pred = clean_prediction(raw_pred, expected_labels)\n",
    "        \n",
    "        if cleaned_pred == y_true:\n",
    "            curr_pred += 1\n",
    "        \n",
    "        print(f\"Sample: True='{y_true}', Raw='{raw_pred}', Cleaned='{cleaned_pred}'\")\n",
    "    \n",
    "    acc = (curr_pred / n_rows) * 100\n",
    "    accuracy_arr.append(acc)\n",
    "\n",
    "    print(f\"\\n=== {prompt_name} Accuracy: {acc:.4f} ===\\n\")\n",
    "    \n",
    "    time.sleep(60)  \n",
    "\n",
    "print(\"Evaluation done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7dcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

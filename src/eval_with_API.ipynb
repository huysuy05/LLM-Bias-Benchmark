{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages (from requests->huggingface_hub) (2025.10.5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install huggingface_hub\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpython\u001b[49m-dotenv\n\u001b[32m      3\u001b[39m scikit-learn\n\u001b[32m      4\u001b[39m torch\n",
      "\u001b[31mNameError\u001b[39m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7445c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huy.suy05./Documents/Projects/LLM_Evals_On_Imbalanced_Datatset/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Fears for T N pension after talks Unions repre...      2\n",
       "1  The Race is On: Second Private Team Sets Launc...      3\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get training dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "df_train.head()\n",
    "\n",
    "# Get testing dataset\n",
    "df_test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5801d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Training Set Label Distribution:\n",
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalanced Training Set Label Distribution:\n",
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Sample out an balanced training data\n",
    "n_rows_per_class = 1000\n",
    "balanced_dfs = []\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique()):\n",
    "    class_samples = df_train[df_train[\"label\"] == label]\n",
    "    balanced_dfs.append(class_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "balanced_data = pd.concat(balanced_dfs)\n",
    "\n",
    "# Sample out an imbalanced training data (Assume label 0 as the majority class)\n",
    "n_majority = 1000\n",
    "n_minority = 1000\n",
    "\n",
    "n_majority_1 = 1000\n",
    "n_minority_1 = 1000\n",
    "\n",
    "imbalanced_dfs = []\n",
    "imbalanced_dfs_1 = []\n",
    "\n",
    "label_0_class = df_train[df_train[\"label\"] == 2] #We pick class 0 as the majority class\n",
    "imbalanced_dfs.append(label_0_class.sample(n_majority, random_state=42))\n",
    "imbalanced_dfs_1.append(label_0_class.sample(n_majority_1, random_state=42))\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique()):\n",
    "    if label != 2:\n",
    "        class_samples = df_train[df_train['label'] == label]\n",
    "        imbalanced_dfs.append(class_samples.sample(n_minority, random_state=42))\n",
    "        imbalanced_dfs_1.append(class_samples.sample(n_minority_1, random_state=42))\n",
    "\n",
    "imbalanced_data = pd.concat(imbalanced_dfs)\n",
    "# Shuffle the imbalanced dataset to mix the classes\n",
    "imbalanced_data = imbalanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "imbalanced_data_5_1_ratio = pd.concat(imbalanced_dfs_1)\n",
    "imbalanced_data_5_1_ratio = imbalanced_data_5_1_ratio.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Training Set Label Distribution:\")\n",
    "print(balanced_data['label'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nImbalanced Training Set Label Distribution:\")\n",
    "print(imbalanced_data['label'].value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "654b1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small testing set\n",
    "n_rows_per_class = 1000\n",
    "test_balanced_dfs = []\n",
    "for label in sorted(df_test[\"label\"].unique()):\n",
    "    test_samples = df_test[df_test[\"label\"] == label]\n",
    "    test_balanced_dfs.append(test_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "testing_set = pd.concat(test_balanced_dfs)\n",
    "testing_set = testing_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "849a9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to build the prompt strings on both balanced and imbalanced\n",
    "label_map = {\n",
    "    0: \"world\",\n",
    "    1: \"sports\",\n",
    "    2: \"business\",\n",
    "    3: \"sci/tech\"\n",
    "}\n",
    "\n",
    "def build_shots_prompt(train_df, shots=None, imbalanced_ratio=None):\n",
    "    prompt_lines = [\"\"\"You are a strict text classification system.\n",
    "\n",
    "                        Task:\n",
    "                        Classify the text into exactly one of these categories:\n",
    "                        - world\n",
    "                        - sports\n",
    "                        - business\n",
    "                        - sci/tech\n",
    "\n",
    "                        Rules:\n",
    "                        1. Output only one label.\n",
    "                        2. The label must be exactly one of: world, sports, business, sci/tech.\n",
    "                        3. The label must be lowercase.\n",
    "                        4. Do not output explanations, punctuation, or extra text.\"\"\"]\n",
    "    \n",
    "    if shots:\n",
    "        # Build a balanced prompt\n",
    "        for label in sorted(train_df['label'].unique()):\n",
    "            class_samples = train_df[train_df['label'] == label].sample(shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "                \n",
    "    elif imbalanced_ratio:\n",
    "        # Build an imbalanced prompt based on the provided ratios\n",
    "        for label, n_shots in imbalanced_ratio.items():\n",
    "            class_samples = train_df[train_df['label'] == label].sample(n_shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "    else:\n",
    "        raise ValueError(\"Must provide either 'shots_per_class' or 'imbalanced_ratios'\")\n",
    "        \n",
    "    # Join all lines into a single string\n",
    "    prompt_str = \"\\n\".join(prompt_lines)\n",
    "    return prompt_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67fad775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(1), np.int64(2), np.int64(3)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(imbalanced_data[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6514beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced_data[\"label\"] = imbalanced_data[\"label\"].map(label_map)\n",
    "# imbalanced_data[\"prompted_text\"] = imbalanced_data.apply(\n",
    "#     lambda row: build_shots_prompt(\n",
    "#         imbalanced_data,\n",
    "#         shots=2\n",
    "#     ) + f\"\\nText: {row['text']}\\nCategory:\",\n",
    "#     axis=1\n",
    "# )\n",
    "testing_set[\"prompted_text\"] = testing_set.apply(\n",
    "    lambda row: build_shots_prompt(\n",
    "        testing_set,\n",
    "        shots=2\n",
    "    ) + f\"\\nText: {row['text']}\\nCategory:\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63a29a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns text\n",
    "# imbalanced_data = imbalanced_data.drop(columns=[\"text\"])\n",
    "# imbalanced_data[\"label\"] = imbalanced_data[\"label\"].map(label_map)\n",
    "# testing_set = testing_set.drop(columns=[\"text\"])\n",
    "testing_set[\"label\"] = testing_set[\"label\"].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5017f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to parquet for later use\n",
    "balanced_data.to_parquet('../Data/ag_news/ag_news_train_balanced.parquet')\n",
    "imbalanced_data.to_parquet('../Data/ag_news/ag_news_train_imbalanced_99_to_1.parquet')\n",
    "testing_set.to_parquet('../Data/ag_news/ag_news_test_small.parquet')\n",
    "imbalanced_data_5_1_ratio.to_parquet('../Data/ag_news/ag_news_train_imbalanced_49_to_1_ratio.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0ef34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, examples_prompt, model_name, api_key):\n",
    "    full_prompt = f\"{examples_prompt}\\n\\nNow classify this new text:\\nText: {text}\\nCategory:\"\n",
    "    payload = {\n",
    "        \"model\": model_name, \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0,  \n",
    "        \"max_tokens\": 1    \n",
    "    }\n",
    "\n",
    "    # The headers required by Open Router\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            data=json.dumps(payload)\n",
    "        )\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        result = response.json()\n",
    "        # Extract the model's response, which is similar to the OpenAI API.\n",
    "        prediction = result['choices'][0]['message']['content'].strip()\n",
    "        pred_lines = prediction.splitlines()[0].lower()\n",
    "        for label in label_map.values():\n",
    "            if label.lower() in pred_lines:\n",
    "                return label\n",
    "        return prediction.strip()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for text '{text[:50]}...': {e}\")\n",
    "        time.sleep(5)  \n",
    "        return \"Error\"\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not parse response for text '{text[:50]}...': {e}. Response: {result}\")\n",
    "        return \"Error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5e21680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EVALUATING nvidia/nemotron-nano-9b-v2:free ---\n",
      "Running with Balanced prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='world', Cleaned='world'\n",
      "\n",
      "=== Balanced Accuracy: 80.0000 ===\n",
      "\n",
      "Running with Imbalanced with 10:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 10:1 Ratio Accuracy: 85.0000 ===\n",
      "\n",
      "Running with Imbalanced with 5:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 5:1 Ratio Accuracy: 80.0000 ===\n",
      "\n",
      "Evaluation done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "model = \"nvidia/nemotron-nano-9b-v2:free\"\n",
    "\n",
    "# Define expected labels to map into the LLM's response\n",
    "expected_labels = list(label_map.values())\n",
    "expected_labels = [lab.lower() for lab in expected_labels]\n",
    "\n",
    "balanced_prompt = build_shots_prompt(balanced_data, shots=2)\n",
    "imbalanced_prompt = build_shots_prompt(balanced_data, imbalanced_ratio={0: 10, 1: 10, 2: 1, 3: 1})\n",
    "imbalanced_prompt_5_to_1 = build_shots_prompt(balanced_data, imbalanced_ratio={0:5, 1:5, 2:1, 3:1})\n",
    "\n",
    "print(f\"--- EVALUATING {model} ---\")\n",
    "model_res = {}\n",
    "\n",
    "def clean_prediction(pred, expected_labels):\n",
    "    if not pred:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Convert to lowercase and remove extra spaces\n",
    "    pred = pred.lower().strip()\n",
    "    \n",
    "    \n",
    "    pred = re.sub(r'[^\\w\\s]', '', pred)  \n",
    "    pred = re.sub(r'\\b(category|is|the|a|an)\\b', '', pred)  \n",
    "    pred = pred.strip()\n",
    "    \n",
    "    \n",
    "    for label in expected_labels:\n",
    "        if label.lower() in pred or pred in label.lower():\n",
    "            return label\n",
    "    \n",
    "   \n",
    "    variation_map = {\n",
    "        'sport': 'Sports',\n",
    "        'sci': 'Sci/Tech',\n",
    "        'technology': 'Sci/Tech',\n",
    "        'tech': 'Sci/Tech',\n",
    "        'businesses': 'Business',\n",
    "        'world news': 'World'\n",
    "    }\n",
    "    \n",
    "    for variation, correct_label in variation_map.items():\n",
    "        if variation in pred:\n",
    "            return correct_label.lower()\n",
    "    \n",
    "    \n",
    "    print(f\"Unrecognized prediction: '{pred}' -> Mapping to 'Unknown'\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "accuracy_arr = []\n",
    "for prompt_name, prompt in [(\"Balanced\", balanced_prompt), (\"Imbalanced with 10:1 Ratio\", imbalanced_prompt), (\"Imbalanced with 5:1 Ratio\", imbalanced_prompt_5_to_1)]:\n",
    "    print(f\"Running with {prompt_name} prompt\\n\")\n",
    "    \n",
    "    curr_pred = 0\n",
    "    n_rows = 20\n",
    "\n",
    "    for _, row in testing_set.iloc[n_rows:41].iterrows():\n",
    "        y_true = label_map[row[\"label\"]].lower()\n",
    "        raw_pred = classify(\n",
    "            text=row[\"text\"],\n",
    "            examples_prompt=prompt,\n",
    "            model_name=model,\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        \n",
    "       \n",
    "        cleaned_pred = clean_prediction(raw_pred, expected_labels)\n",
    "        \n",
    "        if cleaned_pred == y_true:\n",
    "            curr_pred += 1\n",
    "        \n",
    "        print(f\"Sample: True='{y_true}', Raw='{raw_pred}', Cleaned='{cleaned_pred}'\")\n",
    "    \n",
    "    acc = (curr_pred / n_rows) * 100\n",
    "    accuracy_arr.append(acc)\n",
    "\n",
    "    print(f\"\\n=== {prompt_name} Accuracy: {acc:.4f} ===\\n\")\n",
    "    \n",
    "    time.sleep(60)  \n",
    "\n",
    "print(\"Evaluation done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7dcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
